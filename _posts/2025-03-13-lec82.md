---
layout: post_teaching
title: Lecture 13
category: biostat203bwinter2025lec82
---

## Today

* Deploy Docker on cloud.

* GitHub pages.

* Neural networks.

## Feedback on HW4 (thanks to Parsa)

- Q1 - BigQuery

    - Generally good performance on this question.
    
    - A few students were not able to produce the table output in the html or had a few incorrect values in the table.

- Q2 - Shiny Apps

    - Many issues with reproducibility of apps.
    
        - About half of the students did not create an `app.R` file in the mimiciv_shiny folder and instead put all of their shiny app code in the qmd file. Students who did this lost 10 points.
        
        - Forgetting to load in all necessary libraries. Lost 2 points.
        
        - Forgetting to connect to the database within the app file. Lost 5 points.
        
        - Used the variable names themselves instead of a more presentable name in the numerical and graphical summaries (e.g. `marital_status` instead of `Marital Status`. Students who did this lost 5 points.
        
        - Text entry for the patient ids arguments for the graphs instead of a dropdown menu. I marked off 5 points for this since there are too many possibilities for patient ids to make it a text entry.
        
        - Produced incorrect graphs for the patient information (lost 5-20pts depending on severity)
        
- Additional comments

    - One student uploaded the BigQuery token in Git and lost 50 pts.
    
    - One student used collect() before Q1.7 and lost 20 pts.

    - Several students were given +5 bonus points for clean and organized apps.
    
    - Ningke Zhang, Thanh Mai, and Xiangning Deng had the best shiny apps in the class. They all received +10 bonus points.

## Announcements

* [HW5](https://ucla-biostat-203b.github.io/2025winter/hw/hw5/hw5.html) due **Thursday** Mar 20 @ 11:59pm. Start early and ask questions on Slack or office hours. No late submission. 

* HW5 taking too long! Do less exhaustive grid search, or try smarter search strategies. Separate each task into a separate document.

    * Tidymodels: `tune_grid()`, `tune_bayes()` (Bayesian optimization through GP), `tune_sim_anneal()` (simulated annealing), `tune_race_anova()` (racing with ANOVA), `tune_race_win_loss()` (racing with win/loss statistics).

    * Python Scikit-Learn: `GridSearchCV()`, `RandomizedSearchCV()`, ... See [reference](https://scikit-learn.org/stable/modules/classes.html#hyper-parameter-optimizers).
